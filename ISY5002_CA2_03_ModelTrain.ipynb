{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7575215,
     "status": "ok",
     "timestamp": 1569397626716,
     "user": {
      "displayName": "kk L",
      "photoUrl": "",
      "userId": "01076384788128853861"
     },
     "user_tz": -480
    },
    "id": "X97E0JcKgcwc",
    "outputId": "59b2649a-6f26-46f3-afe3-113c7296b99c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# Model Training\n",
    "# 11/09/2019 \n",
    "#\n",
    "#######################################################\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import os\n",
    "from math import floor\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from ISY5002_CA2_02_ModelDefinitions import createModel, my_preprocess\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as VGG16_preprocess_input\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as ResNet50_preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as InceptionV3_preprocess_input\n",
    "\n",
    "# import sys\n",
    "\n",
    "# defining global variables\n",
    "DEBUG_MODE = False\n",
    "image_path = \"./Resized\"\n",
    "seed        = 29 # fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "optmz       = 'adam'    # optimizers.RMSprop(lr=0.0001)\n",
    "modelnameBase   = 'CA2'\n",
    "num_classes = 3\n",
    "\n",
    "channel = 3\n",
    "num_epochs = 100\n",
    "\n",
    "# hyperparameters\n",
    "bsize = 32\n",
    "rng_rot = 0\n",
    "rng_zoom = 0.1\n",
    "rng_bright = [0.01, 0]\n",
    "rng_channel = 0.1\n",
    "opt_hflip = True\n",
    "opt_vflip = False\n",
    "\n",
    "def create_summarise_plot(size, channel, index = 0):\n",
    "    imgrows = size\n",
    "    imgclms = size\n",
    "    model = createModel(imgrows, imgclms, channel, index) # for training\n",
    "    # modelGo = createModel() # for final testing\n",
    "    model.summary()\n",
    "\n",
    "    # Plot structure of network\n",
    "    #from tensorflow.keras.utils import plot_model\n",
    "    #plot_model(model, to_file='ISY5002_CA2_NN_' + str(index) + '.pdf', show_shapes=True, show_layer_names=False, rankdir='TB') \n",
    "\n",
    "    return model\n",
    "\n",
    "def createIterators(size, index=0):\n",
    "    imgrows = size\n",
    "    imgclms = size\n",
    "\n",
    "    preprocessing_fn = my_preprocess\n",
    "    if (index > 90):\n",
    "        # Using pretrained datasets - have to use their preprocess functions\n",
    "        if (index == 90):\n",
    "            preprocessing_fn = VGG16_preprocess_input\n",
    "        elif (index == 91):\n",
    "            preprocessing_fn = ResNet50_preprocess_input\n",
    "        elif (index == 92):\n",
    "            preprocessing_fn = InceptionV3_preprocess_input\n",
    "    datagen = ImageDataGenerator(preprocessing_function = preprocessing_fn)\n",
    "    datagenTrain = ImageDataGenerator(preprocessing_function = preprocessing_fn, \n",
    "        rotation_range=rng_rot, zoom_range=rng_zoom, \n",
    "        horizontal_flip=opt_hflip, vertical_flip=opt_vflip) \n",
    "        #brightness_range = rng_bright, channel_shift_range = rng_channel)\n",
    "    \n",
    "    train_it = datagenTrain.flow_from_directory('./Resized/train/', class_mode='categorical', target_size=(imgrows, imgclms), batch_size=bsize, color_mode='rgb')\n",
    "    val_it = datagen.flow_from_directory('./Resized/validation/', class_mode='categorical', target_size=(imgrows, imgclms), batch_size=bsize, color_mode='rgb')\n",
    "    # test_it = datagen.flow_from_directory('./Resized/test/', class_mode='categorical', target_size=(imgrows, imgclms), batch_size=1, color_mode='rgb')\n",
    "\n",
    "    n_train = sum([len(files) for r, d, files in os.walk('./Resized/train/')])\n",
    "    n_val = sum([len(files) for r, d, files in os.walk('./Resized/validation/')])\n",
    "    # n_test = sum([len(files) for r, d, files in os.walk('./Resized/test/')])\n",
    "\n",
    "    batchX, batchy = train_it.next()\n",
    "    print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
    "\n",
    "    return train_it, val_it, n_train, n_val  \n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # ------ CHANGE THESE ------\n",
    "    index = 90\n",
    "    size = 224\n",
    "    # --------------------------\n",
    "\n",
    "\n",
    "    modelname = modelnameBase + \"_\" + str(index) + \"_\" + str(size)\n",
    "\n",
    "    # Create model and summary\n",
    "    train_it, val_it, n_train, n_val= createIterators(size, index)\n",
    "    model = create_summarise_plot(size, channel, index)\n",
    "\n",
    "    # Create checkpoint for the training\n",
    "    # This checkpoint performs model saving when\n",
    "    # an epoch gives highest testing accuracy\n",
    "    filepath        = modelname + \".hdf5\"\n",
    "    checkpoint      = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "    # Log the epoch detail into csv\n",
    "    csv_logger      = CSVLogger(modelname +'.csv')\n",
    "    callbacks_list  = [checkpoint,csv_logger]\n",
    "    \n",
    "    # steps_per_epoch = total training data across all classes / batch size\n",
    "    # validation_steps = number of batches in validation dataset defining 1 epoch\n",
    "    model.fit_generator(\n",
    "        train_it, steps_per_epoch=floor(n_train/bsize), \n",
    "        validation_data=val_it, \n",
    "        validation_steps=floor(n_val/bsize),\n",
    "        epochs=num_epochs, callbacks = callbacks_list )\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ISY5002_CA2_03_ModelTrain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
