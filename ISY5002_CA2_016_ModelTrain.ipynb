{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7575215,
     "status": "ok",
     "timestamp": 1569397626716,
     "user": {
      "displayName": "kk L",
      "photoUrl": "",
      "userId": "01076384788128853861"
     },
     "user_tz": -480
    },
    "id": "X97E0JcKgcwc",
    "outputId": "59b2649a-6f26-46f3-afe3-113c7296b99c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Wilson\\Data_Analytics\\Master in IS Course\\Master in IS Course\\Pattern Recognition System\\Pattern Recognition CA2\\Wilson\\ISY5002_CA2_02_ModelDefinitions.py:156: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\n",
      "\n",
      "Found 2496 images belonging to 3 classes.\n",
      "Found 624 images belonging to 3 classes.\n",
      "Batch shape=(32, 224, 224, 3), min=-1.841, max=2.330\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_conv (Conv2D)              (None, 224, 224, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_bn (BatchNormalization)    (None, 224, 224, 16) 64          Inpt_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_relu (Activation)          (None, 224, 224, 16) 0           Inpt_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_conv (Conv2D)    (None, 224, 224, 16) 2320        Inpt_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_relu (Activation (None, 224, 224, 16) 0           Stg1_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_add (Add)             (None, 224, 224, 16) 0           Inpt_relu[0][0]                  \n",
      "                                                                 Stg1_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_relu (Activation)     (None, 224, 224, 16) 0           Stg1_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_relu (Activation (None, 224, 224, 16) 0           Stg1_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_add (Add)             (None, 224, 224, 16) 0           Stg1_Blk1_relu[0][0]             \n",
      "                                                                 Stg1_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_relu (Activation)     (None, 224, 224, 16) 0           Stg1_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_relu (Activation (None, 224, 224, 16) 0           Stg1_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_add (Add)             (None, 224, 224, 16) 0           Stg1_Blk2_relu[0][0]             \n",
      "                                                                 Stg1_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_relu (Activation)     (None, 224, 224, 16) 0           Stg1_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_conv (Conv2D)    (None, 112, 112, 32) 4640        Stg1_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_relu (Activation (None, 112, 112, 32) 0           Stg2_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_lin_conv (Conv2D)     (None, 112, 112, 32) 544         Stg1_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_add (Add)             (None, 112, 112, 32) 0           Stg2_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg2_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_relu (Activation)     (None, 112, 112, 32) 0           Stg2_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_relu (Activation (None, 112, 112, 32) 0           Stg2_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_add (Add)             (None, 112, 112, 32) 0           Stg2_Blk1_relu[0][0]             \n",
      "                                                                 Stg2_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_relu (Activation)     (None, 112, 112, 32) 0           Stg2_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_relu (Activation (None, 112, 112, 32) 0           Stg2_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_add (Add)             (None, 112, 112, 32) 0           Stg2_Blk2_relu[0][0]             \n",
      "                                                                 Stg2_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_relu (Activation)     (None, 112, 112, 32) 0           Stg2_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_relu (Activation (None, 112, 112, 32) 0           Stg2_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res2_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res2_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_add (Add)             (None, 112, 112, 32) 0           Stg2_Blk3_relu[0][0]             \n",
      "                                                                 Stg2_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_relu (Activation)     (None, 112, 112, 32) 0           Stg2_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_relu (Activation (None, 112, 112, 32) 0           Stg2_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res2_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res2_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_add (Add)             (None, 112, 112, 32) 0           Stg2_Blk4_relu[0][0]             \n",
      "                                                                 Stg2_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_relu (Activation)     (None, 112, 112, 32) 0           Stg2_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_conv (Conv2D)    (None, 56, 56, 64)   18496       Stg2_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_lin_conv (Conv2D)     (None, 56, 56, 64)   2112        Stg2_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg3_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk1_relu[0][0]             \n",
      "                                                                 Stg3_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk2_relu[0][0]             \n",
      "                                                                 Stg3_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk3_relu[0][0]             \n",
      "                                                                 Stg3_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk4_relu[0][0]             \n",
      "                                                                 Stg3_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "AvgPool (AveragePooling2D)      (None, 7, 7, 64)     0           Stg3_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           AvgPool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1606144     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128)          512         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            387         batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 2,301,187\n",
      "Trainable params: 2,296,739\n",
      "Non-trainable params: 4,448\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "78/78 [==============================] - 44s 563ms/step - loss: 12.2859 - acc: 0.6143 - val_loss: 9.2894 - val_acc: 0.5658\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 28s 361ms/step - loss: 6.7706 - acc: 0.6214 - val_loss: 5.5320 - val_acc: 0.6420\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 28s 362ms/step - loss: 4.5767 - acc: 0.6542 - val_loss: 3.8711 - val_acc: 0.6727\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 3.3652 - acc: 0.6794 - val_loss: 2.9303 - val_acc: 0.6963\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 2.5882 - acc: 0.6911 - val_loss: 2.2601 - val_acc: 0.7133\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 28s 361ms/step - loss: 2.0293 - acc: 0.7141 - val_loss: 1.8337 - val_acc: 0.6974\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 1.6571 - acc: 0.7292 - val_loss: 1.5713 - val_acc: 0.6930\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 1.3847 - acc: 0.7350 - val_loss: 1.2684 - val_acc: 0.7511\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 28s 363ms/step - loss: 1.2013 - acc: 0.7448 - val_loss: 1.2134 - val_acc: 0.7363\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 1.0765 - acc: 0.7461 - val_loss: 1.0637 - val_acc: 0.7275\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.9884 - acc: 0.7504 - val_loss: 0.9543 - val_acc: 0.7407\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 29s 368ms/step - loss: 0.9264 - acc: 0.7536 - val_loss: 1.0001 - val_acc: 0.7286\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 29s 370ms/step - loss: 0.8643 - acc: 0.7611 - val_loss: 0.8478 - val_acc: 0.7632\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 0.8325 - acc: 0.7716 - val_loss: 0.9556 - val_acc: 0.7127\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 0.8171 - acc: 0.7728 - val_loss: 0.8968 - val_acc: 0.7045\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.7908 - acc: 0.7794 - val_loss: 2.1078 - val_acc: 0.5850\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.7990 - acc: 0.7762 - val_loss: 0.8786 - val_acc: 0.7341\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.7810 - acc: 0.7799 - val_loss: 5.1489 - val_acc: 0.5570\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 29s 370ms/step - loss: 0.7462 - acc: 0.7911 - val_loss: 0.7691 - val_acc: 0.7911\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 29s 368ms/step - loss: 0.7493 - acc: 0.7878 - val_loss: 0.7401 - val_acc: 0.7982\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 29s 365ms/step - loss: 0.7335 - acc: 0.7985 - val_loss: 0.9751 - val_acc: 0.6913\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.7436 - acc: 0.7995 - val_loss: 0.7755 - val_acc: 0.7796\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.7331 - acc: 0.7938 - val_loss: 0.8623 - val_acc: 0.7018\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 29s 368ms/step - loss: 0.7048 - acc: 0.8029 - val_loss: 0.7148 - val_acc: 0.8087\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.6819 - acc: 0.8092 - val_loss: 1.2702 - val_acc: 0.6568\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 28s 363ms/step - loss: 0.7109 - acc: 0.7991 - val_loss: 0.8051 - val_acc: 0.7577\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.6941 - acc: 0.8120 - val_loss: 0.7540 - val_acc: 0.7917\n",
      "Epoch 28/100\n",
      "78/78 [==============================] - 29s 365ms/step - loss: 0.6742 - acc: 0.8108 - val_loss: 0.7980 - val_acc: 0.7209\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.6680 - acc: 0.8142 - val_loss: 0.7897 - val_acc: 0.7478\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - 29s 368ms/step - loss: 0.6657 - acc: 0.8157 - val_loss: 0.6134 - val_acc: 0.8421\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.6540 - acc: 0.8213 - val_loss: 1.0637 - val_acc: 0.7056\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.6483 - acc: 0.8221 - val_loss: 0.6897 - val_acc: 0.7944\n",
      "Epoch 33/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.6572 - acc: 0.8176 - val_loss: 0.6431 - val_acc: 0.8279\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.6321 - acc: 0.8303 - val_loss: 0.6200 - val_acc: 0.8257\n",
      "Epoch 35/100\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 0.6199 - acc: 0.8291 - val_loss: 0.6927 - val_acc: 0.7730\n",
      "Epoch 36/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.6254 - acc: 0.8271 - val_loss: 0.8338 - val_acc: 0.7791\n",
      "Epoch 37/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.6121 - acc: 0.8331 - val_loss: 1.0059 - val_acc: 0.7182\n",
      "Epoch 38/100\n",
      "78/78 [==============================] - 29s 365ms/step - loss: 0.6025 - acc: 0.8328 - val_loss: 0.9608 - val_acc: 0.7111\n",
      "Epoch 39/100\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 0.6095 - acc: 0.8325 - val_loss: 0.6378 - val_acc: 0.8218\n",
      "Epoch 40/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.6203 - acc: 0.8248 - val_loss: 0.7807 - val_acc: 0.7303\n",
      "Epoch 41/100\n",
      "78/78 [==============================] - 29s 369ms/step - loss: 0.5942 - acc: 0.8466 - val_loss: 0.7715 - val_acc: 0.7681\n",
      "Epoch 42/100\n",
      "78/78 [==============================] - 29s 372ms/step - loss: 0.5951 - acc: 0.8365 - val_loss: 1.0445 - val_acc: 0.6716\n",
      "Epoch 43/100\n",
      "78/78 [==============================] - 29s 367ms/step - loss: 0.5830 - acc: 0.8389 - val_loss: 0.6777 - val_acc: 0.8021\n",
      "Epoch 44/100\n",
      "78/78 [==============================] - 29s 365ms/step - loss: 0.5788 - acc: 0.8376 - val_loss: 0.8388 - val_acc: 0.7478\n",
      "Epoch 45/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.5539 - acc: 0.8498 - val_loss: 0.6396 - val_acc: 0.8004\n",
      "Epoch 46/100\n",
      "78/78 [==============================] - 29s 367ms/step - loss: 0.5837 - acc: 0.8412 - val_loss: 0.9951 - val_acc: 0.7138\n",
      "Epoch 47/100\n",
      "78/78 [==============================] - 29s 370ms/step - loss: 0.5601 - acc: 0.8500 - val_loss: 1.2293 - val_acc: 0.6387\n",
      "Epoch 48/100\n",
      "78/78 [==============================] - 29s 373ms/step - loss: 0.5991 - acc: 0.8377 - val_loss: 0.9808 - val_acc: 0.7654\n",
      "Epoch 49/100\n",
      "78/78 [==============================] - 29s 370ms/step - loss: 0.5800 - acc: 0.8419 - val_loss: 0.8420 - val_acc: 0.7467\n",
      "Epoch 50/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.5364 - acc: 0.8554 - val_loss: 0.7896 - val_acc: 0.7445\n",
      "Epoch 51/100\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 0.5336 - acc: 0.8558 - val_loss: 0.6025 - val_acc: 0.8213\n",
      "Epoch 52/100\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 0.5421 - acc: 0.8514 - val_loss: 0.6408 - val_acc: 0.8070\n",
      "Epoch 53/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.5460 - acc: 0.8547 - val_loss: 0.6469 - val_acc: 0.8010\n",
      "Epoch 54/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.5574 - acc: 0.8488 - val_loss: 0.8745 - val_acc: 0.7237\n",
      "Epoch 55/100\n",
      "78/78 [==============================] - 29s 367ms/step - loss: 0.5187 - acc: 0.8562 - val_loss: 0.9361 - val_acc: 0.7527\n",
      "Epoch 56/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.5222 - acc: 0.8595 - val_loss: 0.8720 - val_acc: 0.7039\n",
      "Epoch 57/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.5194 - acc: 0.8594 - val_loss: 0.6479 - val_acc: 0.7977\n",
      "Epoch 58/100\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 0.5297 - acc: 0.8575 - val_loss: 0.7126 - val_acc: 0.7615\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 28s 364ms/step - loss: 0.5422 - acc: 0.8604 - val_loss: 1.4534 - val_acc: 0.6820\n",
      "Epoch 60/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.5295 - acc: 0.8599 - val_loss: 0.6713 - val_acc: 0.7654\n",
      "Epoch 61/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.5211 - acc: 0.8610 - val_loss: 0.6705 - val_acc: 0.8021\n",
      "Epoch 62/100\n",
      "78/78 [==============================] - 29s 368ms/step - loss: 0.5128 - acc: 0.8612 - val_loss: 0.5583 - val_acc: 0.8438\n",
      "Epoch 63/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.5235 - acc: 0.8558 - val_loss: 0.6126 - val_acc: 0.8394\n",
      "Epoch 64/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.5137 - acc: 0.8646 - val_loss: 0.5737 - val_acc: 0.8322\n",
      "Epoch 65/100\n",
      "78/78 [==============================] - 29s 369ms/step - loss: 0.5264 - acc: 0.8563 - val_loss: 0.5824 - val_acc: 0.8503\n",
      "Epoch 66/100\n",
      "78/78 [==============================] - 29s 365ms/step - loss: 0.5057 - acc: 0.8681 - val_loss: 0.6657 - val_acc: 0.7895\n",
      "Epoch 67/100\n",
      "78/78 [==============================] - 29s 367ms/step - loss: 0.5027 - acc: 0.8677 - val_loss: 0.6667 - val_acc: 0.7741\n",
      "Epoch 68/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.4947 - acc: 0.8659 - val_loss: 0.5384 - val_acc: 0.8333\n",
      "Epoch 69/100\n",
      "78/78 [==============================] - 29s 365ms/step - loss: 0.4982 - acc: 0.8657 - val_loss: 0.7170 - val_acc: 0.8043\n",
      "Epoch 70/100\n",
      "78/78 [==============================] - 29s 367ms/step - loss: 0.5068 - acc: 0.8665 - val_loss: 0.5377 - val_acc: 0.8509\n",
      "Epoch 71/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.5059 - acc: 0.8675 - val_loss: 1.1991 - val_acc: 0.6612\n",
      "Epoch 72/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.5066 - acc: 0.8669 - val_loss: 1.0475 - val_acc: 0.6732\n",
      "Epoch 73/100\n",
      "78/78 [==============================] - 29s 365ms/step - loss: 0.4889 - acc: 0.8710 - val_loss: 0.5967 - val_acc: 0.8229\n",
      "Epoch 74/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.5291 - acc: 0.8568 - val_loss: 0.6443 - val_acc: 0.7884\n",
      "Epoch 75/100\n",
      "78/78 [==============================] - 29s 372ms/step - loss: 0.5013 - acc: 0.8651 - val_loss: 0.6889 - val_acc: 0.7741\n",
      "Epoch 76/100\n",
      "78/78 [==============================] - 29s 372ms/step - loss: 0.4856 - acc: 0.8799 - val_loss: 0.6787 - val_acc: 0.8081\n",
      "Epoch 77/100\n",
      "78/78 [==============================] - 29s 370ms/step - loss: 0.5119 - acc: 0.8655 - val_loss: 0.8628 - val_acc: 0.7275\n",
      "Epoch 78/100\n",
      "78/78 [==============================] - 29s 375ms/step - loss: 0.4769 - acc: 0.8825 - val_loss: 0.5184 - val_acc: 0.8596\n",
      "Epoch 79/100\n",
      "78/78 [==============================] - 29s 374ms/step - loss: 0.4932 - acc: 0.8742 - val_loss: 0.5091 - val_acc: 0.8646\n",
      "Epoch 80/100\n",
      "78/78 [==============================] - 29s 369ms/step - loss: 0.4930 - acc: 0.8662 - val_loss: 0.6909 - val_acc: 0.8026\n",
      "Epoch 81/100\n",
      "78/78 [==============================] - 29s 375ms/step - loss: 0.4824 - acc: 0.8749 - val_loss: 0.5101 - val_acc: 0.8761\n",
      "Epoch 82/100\n",
      "78/78 [==============================] - 29s 373ms/step - loss: 0.4870 - acc: 0.8722 - val_loss: 0.6403 - val_acc: 0.8141\n",
      "Epoch 83/100\n",
      "78/78 [==============================] - 29s 370ms/step - loss: 0.4866 - acc: 0.8789 - val_loss: 0.6381 - val_acc: 0.8158\n",
      "Epoch 84/100\n",
      "78/78 [==============================] - 29s 372ms/step - loss: 0.4869 - acc: 0.8751 - val_loss: 0.5027 - val_acc: 0.8728\n",
      "Epoch 85/100\n",
      "78/78 [==============================] - 29s 375ms/step - loss: 0.4792 - acc: 0.8789 - val_loss: 0.4636 - val_acc: 0.8865\n",
      "Epoch 86/100\n",
      "78/78 [==============================] - 29s 372ms/step - loss: 0.4735 - acc: 0.8715 - val_loss: 0.5286 - val_acc: 0.8536\n",
      "Epoch 87/100\n",
      "78/78 [==============================] - 29s 372ms/step - loss: 0.4796 - acc: 0.8686 - val_loss: 1.1209 - val_acc: 0.6946\n",
      "Epoch 88/100\n",
      "78/78 [==============================] - 29s 372ms/step - loss: 0.4735 - acc: 0.8797 - val_loss: 0.4402 - val_acc: 0.8876\n",
      "Epoch 89/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.4677 - acc: 0.8854 - val_loss: 0.5240 - val_acc: 0.8454\n",
      "Epoch 90/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.4962 - acc: 0.8735 - val_loss: 1.0414 - val_acc: 0.7264\n",
      "Epoch 91/100\n",
      "78/78 [==============================] - 29s 367ms/step - loss: 0.4813 - acc: 0.8797 - val_loss: 0.5981 - val_acc: 0.8196\n",
      "Epoch 92/100\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 0.4791 - acc: 0.8766 - val_loss: 0.6057 - val_acc: 0.8279\n",
      "Epoch 93/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.4727 - acc: 0.8782 - val_loss: 0.5893 - val_acc: 0.8531\n",
      "Epoch 94/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.4944 - acc: 0.8747 - val_loss: 0.7742 - val_acc: 0.7791\n",
      "Epoch 95/100\n",
      "78/78 [==============================] - 29s 365ms/step - loss: 0.4656 - acc: 0.8874 - val_loss: 0.5211 - val_acc: 0.8558\n",
      "Epoch 96/100\n",
      "78/78 [==============================] - 28s 364ms/step - loss: 0.4521 - acc: 0.8933 - val_loss: 0.9787 - val_acc: 0.6859\n",
      "Epoch 97/100\n",
      "78/78 [==============================] - 28s 365ms/step - loss: 0.4728 - acc: 0.8851 - val_loss: 0.6602 - val_acc: 0.7675\n",
      "Epoch 98/100\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 0.4633 - acc: 0.8787 - val_loss: 0.8432 - val_acc: 0.7692\n",
      "Epoch 99/100\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 0.4576 - acc: 0.8884 - val_loss: 0.6662 - val_acc: 0.7971\n",
      "Epoch 100/100\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 0.4613 - acc: 0.8850 - val_loss: 0.8352 - val_acc: 0.7741\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "# Model Training\n",
    "# 11/09/2019 \n",
    "#\n",
    "#######################################################\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import os\n",
    "from math import floor\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from ISY5002_CA2_02_ModelDefinitions import createModel, my_preprocess\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as VGG16_preprocess_input\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as ResNet50_preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as InceptionV3_preprocess_input\n",
    "\n",
    "# import sys\n",
    "\n",
    "# defining global variables\n",
    "DEBUG_MODE = False\n",
    "image_path = \"./Resized\"\n",
    "seed        = 29 # fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "optmz       = 'adam'    # optimizers.RMSprop(lr=0.0001)\n",
    "modelnameBase   = 'CA2'\n",
    "num_classes = 3\n",
    "\n",
    "channel = 3\n",
    "num_epochs = 100\n",
    "\n",
    "# hyperparameters\n",
    "bsize = 32\n",
    "rng_rot = 0\n",
    "rng_zoom = 0.1\n",
    "rng_bright = [0.01, 0]\n",
    "rng_channel = 0.1\n",
    "opt_hflip = True\n",
    "opt_vflip = False\n",
    "\n",
    "def create_summarise_plot(size, channel, index = 0):\n",
    "    imgrows = size\n",
    "    imgclms = size\n",
    "    model = createModel(imgrows, imgclms, channel, index) # for training\n",
    "    # modelGo = createModel() # for final testing\n",
    "    model.summary()\n",
    "\n",
    "    # Plot structure of network\n",
    "    #from tensorflow.keras.utils import plot_model\n",
    "    #plot_model(model, to_file='ISY5002_CA2_NN_' + str(index) + '.pdf', show_shapes=True, show_layer_names=False, rankdir='TB') \n",
    "\n",
    "    return model\n",
    "\n",
    "def createIterators(size, index=0):\n",
    "    imgrows = size\n",
    "    imgclms = size\n",
    "\n",
    "    preprocessing_fn = my_preprocess\n",
    "    if (index > 90):\n",
    "        # Using pretrained datasets - have to use their preprocess functions\n",
    "        if (index == 90):\n",
    "            preprocessing_fn = VGG16_preprocess_input\n",
    "        elif (index == 91):\n",
    "            preprocessing_fn = ResNet50_preprocess_input\n",
    "        elif (index == 92):\n",
    "            preprocessing_fn = InceptionV3_preprocess_input\n",
    "    datagen = ImageDataGenerator(preprocessing_function = preprocessing_fn)\n",
    "    datagenTrain = ImageDataGenerator(preprocessing_function = preprocessing_fn, \n",
    "        rotation_range=rng_rot, zoom_range=rng_zoom, \n",
    "        horizontal_flip=opt_hflip, vertical_flip=opt_vflip) \n",
    "        #brightness_range = rng_bright, channel_shift_range = rng_channel)\n",
    "    \n",
    "    train_it = datagenTrain.flow_from_directory('./Resized/train/', class_mode='categorical', target_size=(imgrows, imgclms), batch_size=bsize, color_mode='rgb')\n",
    "    val_it = datagen.flow_from_directory('./Resized/validation/', class_mode='categorical', target_size=(imgrows, imgclms), batch_size=bsize, color_mode='rgb')\n",
    "    # test_it = datagen.flow_from_directory('./Resized/test/', class_mode='categorical', target_size=(imgrows, imgclms), batch_size=1, color_mode='rgb')\n",
    "\n",
    "    n_train = sum([len(files) for r, d, files in os.walk('./Resized/train/')])\n",
    "    n_val = sum([len(files) for r, d, files in os.walk('./Resized/validation/')])\n",
    "    # n_test = sum([len(files) for r, d, files in os.walk('./Resized/test/')])\n",
    "\n",
    "    batchX, batchy = train_it.next()\n",
    "    print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
    "\n",
    "    return train_it, val_it, n_train, n_val  \n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # ------ CHANGE THESE ------\n",
    "    index = 16\n",
    "    size = 224\n",
    "    # --------------------------\n",
    "\n",
    "\n",
    "    modelname = modelnameBase + \"_\" + str(index) + \"_\" + str(size)\n",
    "\n",
    "    # Create model and summary\n",
    "    train_it, val_it, n_train, n_val= createIterators(size, index)\n",
    "    model = create_summarise_plot(size, channel, index)\n",
    "\n",
    "    # Create checkpoint for the training\n",
    "    # This checkpoint performs model saving when\n",
    "    # an epoch gives highest testing accuracy\n",
    "    filepath        = modelname + \".hdf5\"\n",
    "    checkpoint      = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "    # Log the epoch detail into csv\n",
    "    csv_logger      = CSVLogger(modelname +'.csv')\n",
    "    callbacks_list  = [checkpoint,csv_logger]\n",
    "    \n",
    "    # steps_per_epoch = total training data across all classes / batch size\n",
    "    # validation_steps = number of batches in validation dataset defining 1 epoch\n",
    "    model.fit_generator(\n",
    "        train_it, steps_per_epoch=floor(n_train/bsize), \n",
    "        validation_data=val_it, \n",
    "        validation_steps=floor(n_val/bsize),\n",
    "        epochs=num_epochs, callbacks = callbacks_list )\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ISY5002_CA2_03_ModelTrain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
