{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7575215,
     "status": "ok",
     "timestamp": 1569397626716,
     "user": {
      "displayName": "kk L",
      "photoUrl": "",
      "userId": "01076384788128853861"
     },
     "user_tz": -480
    },
    "id": "X97E0JcKgcwc",
    "outputId": "59b2649a-6f26-46f3-afe3-113c7296b99c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Wilson\\Data_Analytics\\Master in IS Course\\Master in IS Course\\Pattern Recognition System\\Pattern Recognition CA2\\Wilson\\ISY5002_CA2_02_ModelDefinitions.py:156: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\n",
      "\n",
      "Found 2496 images belonging to 3 classes.\n",
      "Found 624 images belonging to 3 classes.\n",
      "Batch shape=(32, 224, 224, 3), min=-1.841, max=2.330\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_conv (Conv2D)              (None, 224, 224, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_bn (BatchNormalization)    (None, 224, 224, 16) 64          Inpt_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_relu (Activation)          (None, 224, 224, 16) 0           Inpt_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_conv (Conv2D)    (None, 224, 224, 16) 2320        Inpt_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_relu (Activation (None, 224, 224, 16) 0           Stg1_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_add (Add)             (None, 224, 224, 16) 0           Inpt_relu[0][0]                  \n",
      "                                                                 Stg1_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_relu (Activation)     (None, 224, 224, 16) 0           Stg1_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_relu (Activation (None, 224, 224, 16) 0           Stg1_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_add (Add)             (None, 224, 224, 16) 0           Stg1_Blk1_relu[0][0]             \n",
      "                                                                 Stg1_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_relu (Activation)     (None, 224, 224, 16) 0           Stg1_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_relu (Activation (None, 224, 224, 16) 0           Stg1_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_add (Add)             (None, 224, 224, 16) 0           Stg1_Blk2_relu[0][0]             \n",
      "                                                                 Stg1_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_relu (Activation)     (None, 224, 224, 16) 0           Stg1_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res1_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res1_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res1_relu (Activation (None, 224, 224, 16) 0           Stg1_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res2_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res2_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_add (Add)             (None, 224, 224, 16) 0           Stg1_Blk3_relu[0][0]             \n",
      "                                                                 Stg1_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_relu (Activation)     (None, 224, 224, 16) 0           Stg1_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res1_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res1_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res1_relu (Activation (None, 224, 224, 16) 0           Stg1_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res2_conv (Conv2D)    (None, 224, 224, 16) 2320        Stg1_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res2_bn (BatchNormali (None, 224, 224, 16) 64          Stg1_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_add (Add)             (None, 224, 224, 16) 0           Stg1_Blk4_relu[0][0]             \n",
      "                                                                 Stg1_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_relu (Activation)     (None, 224, 224, 16) 0           Stg1_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_conv (Conv2D)    (None, 112, 112, 32) 4640        Stg1_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_relu (Activation (None, 112, 112, 32) 0           Stg2_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_lin_conv (Conv2D)     (None, 112, 112, 32) 544         Stg1_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_add (Add)             (None, 112, 112, 32) 0           Stg2_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg2_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_relu (Activation)     (None, 112, 112, 32) 0           Stg2_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_relu (Activation (None, 112, 112, 32) 0           Stg2_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_add (Add)             (None, 112, 112, 32) 0           Stg2_Blk1_relu[0][0]             \n",
      "                                                                 Stg2_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_relu (Activation)     (None, 112, 112, 32) 0           Stg2_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_relu (Activation (None, 112, 112, 32) 0           Stg2_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_add (Add)             (None, 112, 112, 32) 0           Stg2_Blk2_relu[0][0]             \n",
      "                                                                 Stg2_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_relu (Activation)     (None, 112, 112, 32) 0           Stg2_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_relu (Activation (None, 112, 112, 32) 0           Stg2_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res2_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res2_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_add (Add)             (None, 112, 112, 32) 0           Stg2_Blk3_relu[0][0]             \n",
      "                                                                 Stg2_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_relu (Activation)     (None, 112, 112, 32) 0           Stg2_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_relu (Activation (None, 112, 112, 32) 0           Stg2_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res2_conv (Conv2D)    (None, 112, 112, 32) 9248        Stg2_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res2_bn (BatchNormali (None, 112, 112, 32) 128         Stg2_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_add (Add)             (None, 112, 112, 32) 0           Stg2_Blk4_relu[0][0]             \n",
      "                                                                 Stg2_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_relu (Activation)     (None, 112, 112, 32) 0           Stg2_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_conv (Conv2D)    (None, 56, 56, 64)   18496       Stg2_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_lin_conv (Conv2D)     (None, 56, 56, 64)   2112        Stg2_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg3_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk1_relu[0][0]             \n",
      "                                                                 Stg3_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk2_relu[0][0]             \n",
      "                                                                 Stg3_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk3_relu[0][0]             \n",
      "                                                                 Stg3_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk4_relu[0][0]             \n",
      "                                                                 Stg3_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk6_Res1_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk6_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk6_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk6_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk6_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk6_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk6_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk6_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk6_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk6_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk5_relu[0][0]             \n",
      "                                                                 Stg3_Blk6_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk6_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk6_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk7_Res1_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk6_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk7_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk7_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk7_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk7_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk7_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk7_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk7_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk7_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk7_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk6_relu[0][0]             \n",
      "                                                                 Stg3_Blk7_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk7_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk7_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk8_Res1_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk7_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk8_Res1_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk8_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk8_Res1_relu (Activation (None, 56, 56, 64)   0           Stg3_Blk8_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk8_Res2_conv (Conv2D)    (None, 56, 56, 64)   36928       Stg3_Blk8_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk8_Res2_bn (BatchNormali (None, 56, 56, 64)   256         Stg3_Blk8_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk8_add (Add)             (None, 56, 56, 64)   0           Stg3_Blk7_relu[0][0]             \n",
      "                                                                 Stg3_Blk8_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk8_relu (Activation)     (None, 56, 56, 64)   0           Stg3_Blk8_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "AvgPool (AveragePooling2D)      (None, 7, 7, 64)     0           Stg3_Blk8_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           AvgPool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1606144     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128)          512         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          16512       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3)            387         batch_normalization_5[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 2,567,875\n",
      "Trainable params: 2,562,019\n",
      "Non-trainable params: 5,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "78/78 [==============================] - 61s 776ms/step - loss: 15.9274 - acc: 0.5860 - val_loss: 15.5679 - val_acc: 0.5559\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 39s 495ms/step - loss: 10.3938 - acc: 0.6179 - val_loss: 8.7319 - val_acc: 0.6579\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 39s 497ms/step - loss: 7.5245 - acc: 0.6241 - val_loss: 6.4945 - val_acc: 0.6754\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 39s 495ms/step - loss: 5.7485 - acc: 0.6361 - val_loss: 5.0189 - val_acc: 0.6672\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 39s 496ms/step - loss: 4.4812 - acc: 0.6558 - val_loss: 3.9438 - val_acc: 0.6749\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 39s 497ms/step - loss: 3.5039 - acc: 0.6760 - val_loss: 3.1090 - val_acc: 0.6749\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 2.8049 - acc: 0.6798 - val_loss: 2.5401 - val_acc: 0.6700\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 39s 498ms/step - loss: 2.2986 - acc: 0.6798 - val_loss: 2.0878 - val_acc: 0.6711\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 1.8784 - acc: 0.6972 - val_loss: 1.7576 - val_acc: 0.6749\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 1.5929 - acc: 0.7105 - val_loss: 1.5265 - val_acc: 0.6661\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 1.4114 - acc: 0.7035 - val_loss: 1.3740 - val_acc: 0.6705\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 1.2755 - acc: 0.7065 - val_loss: 1.2416 - val_acc: 0.6743\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 39s 505ms/step - loss: 1.1489 - acc: 0.7177 - val_loss: 1.1262 - val_acc: 0.6968\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 39s 504ms/step - loss: 1.0734 - acc: 0.7264 - val_loss: 1.0659 - val_acc: 0.7029\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 1.0354 - acc: 0.7337 - val_loss: 1.0616 - val_acc: 0.6952\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 39s 504ms/step - loss: 0.9980 - acc: 0.7425 - val_loss: 0.9916 - val_acc: 0.7325\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.9790 - acc: 0.7401 - val_loss: 0.9700 - val_acc: 0.7083\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 39s 504ms/step - loss: 0.9065 - acc: 0.7588 - val_loss: 0.9341 - val_acc: 0.7675\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.8893 - acc: 0.7551 - val_loss: 0.9051 - val_acc: 0.7451\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.8801 - acc: 0.7555 - val_loss: 0.8903 - val_acc: 0.7467\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 39s 505ms/step - loss: 0.8589 - acc: 0.7618 - val_loss: 0.8348 - val_acc: 0.7692\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 39s 503ms/step - loss: 0.8683 - acc: 0.7592 - val_loss: 1.4076 - val_acc: 0.6628\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 40s 507ms/step - loss: 0.8617 - acc: 0.7648 - val_loss: 0.8960 - val_acc: 0.7555\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.8274 - acc: 0.7760 - val_loss: 0.9608 - val_acc: 0.6694\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.8397 - acc: 0.7827 - val_loss: 0.9199 - val_acc: 0.7473\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.8268 - acc: 0.7825 - val_loss: 1.5937 - val_acc: 0.6716\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 39s 502ms/step - loss: 0.8172 - acc: 0.7883 - val_loss: 0.9085 - val_acc: 0.7593\n",
      "Epoch 28/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.8150 - acc: 0.7911 - val_loss: 1.0589 - val_acc: 0.7094\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - 39s 503ms/step - loss: 0.7966 - acc: 0.7897 - val_loss: 0.8555 - val_acc: 0.7434\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - 40s 510ms/step - loss: 0.7778 - acc: 0.7941 - val_loss: 0.8533 - val_acc: 0.7423\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - 39s 503ms/step - loss: 0.7661 - acc: 0.8093 - val_loss: 1.0410 - val_acc: 0.7160\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.8300 - acc: 0.7837 - val_loss: 1.4905 - val_acc: 0.6628\n",
      "Epoch 33/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.7832 - acc: 0.8037 - val_loss: 1.3526 - val_acc: 0.6469\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - 39s 504ms/step - loss: 0.7697 - acc: 0.8013 - val_loss: 0.7533 - val_acc: 0.8043\n",
      "Epoch 35/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.7618 - acc: 0.8024 - val_loss: 0.9678 - val_acc: 0.6831\n",
      "Epoch 36/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.7369 - acc: 0.8064 - val_loss: 1.0973 - val_acc: 0.6711\n",
      "Epoch 37/100\n",
      "78/78 [==============================] - 39s 503ms/step - loss: 0.7322 - acc: 0.8128 - val_loss: 0.8377 - val_acc: 0.7555\n",
      "Epoch 38/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.7303 - acc: 0.8093 - val_loss: 0.8467 - val_acc: 0.7379\n",
      "Epoch 39/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.7287 - acc: 0.8144 - val_loss: 0.8440 - val_acc: 0.7643\n",
      "Epoch 40/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.7357 - acc: 0.8121 - val_loss: 1.0597 - val_acc: 0.6924\n",
      "Epoch 41/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.7536 - acc: 0.8042 - val_loss: 0.8098 - val_acc: 0.7440\n",
      "Epoch 42/100\n",
      "78/78 [==============================] - 40s 506ms/step - loss: 0.7141 - acc: 0.8257 - val_loss: 0.8943 - val_acc: 0.7336\n",
      "Epoch 43/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.7133 - acc: 0.8169 - val_loss: 0.8245 - val_acc: 0.7462\n",
      "Epoch 44/100\n",
      "78/78 [==============================] - 39s 504ms/step - loss: 0.6938 - acc: 0.8198 - val_loss: 0.6715 - val_acc: 0.8257\n",
      "Epoch 45/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6829 - acc: 0.8297 - val_loss: 0.8763 - val_acc: 0.7385\n",
      "Epoch 46/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6975 - acc: 0.8217 - val_loss: 0.7834 - val_acc: 0.7834\n",
      "Epoch 47/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6860 - acc: 0.8204 - val_loss: 2.9488 - val_acc: 0.5779\n",
      "Epoch 48/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6934 - acc: 0.8231 - val_loss: 0.8667 - val_acc: 0.7538\n",
      "Epoch 49/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6740 - acc: 0.8264 - val_loss: 0.9490 - val_acc: 0.7039\n",
      "Epoch 50/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6738 - acc: 0.8296 - val_loss: 0.6692 - val_acc: 0.8147\n",
      "Epoch 51/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.6839 - acc: 0.8133 - val_loss: 4.1112 - val_acc: 0.5592\n",
      "Epoch 52/100\n",
      "78/78 [==============================] - 39s 503ms/step - loss: 0.6882 - acc: 0.8275 - val_loss: 1.2763 - val_acc: 0.6902\n",
      "Epoch 53/100\n",
      "78/78 [==============================] - 39s 503ms/step - loss: 0.6534 - acc: 0.8312 - val_loss: 0.7771 - val_acc: 0.7248\n",
      "Epoch 54/100\n",
      "78/78 [==============================] - 39s 502ms/step - loss: 0.6271 - acc: 0.8357 - val_loss: 0.7068 - val_acc: 0.7769\n",
      "Epoch 55/100\n",
      "78/78 [==============================] - 40s 506ms/step - loss: 0.6354 - acc: 0.8369 - val_loss: 1.1224 - val_acc: 0.6349\n",
      "Epoch 56/100\n",
      "78/78 [==============================] - 39s 502ms/step - loss: 0.6505 - acc: 0.8251 - val_loss: 0.7376 - val_acc: 0.7834\n",
      "Epoch 57/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6536 - acc: 0.8327 - val_loss: 0.7299 - val_acc: 0.7878\n",
      "Epoch 58/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6689 - acc: 0.8208 - val_loss: 0.7474 - val_acc: 0.7396\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6627 - acc: 0.8296 - val_loss: 3.3917 - val_acc: 0.6409\n",
      "Epoch 60/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6572 - acc: 0.8295 - val_loss: 0.9101 - val_acc: 0.7336\n",
      "Epoch 61/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6955 - acc: 0.8243 - val_loss: 0.7778 - val_acc: 0.8224\n",
      "Epoch 62/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.7113 - acc: 0.8289 - val_loss: 1.0478 - val_acc: 0.6979\n",
      "Epoch 63/100\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.6474 - acc: 0.8348 - val_loss: 0.6740 - val_acc: 0.8004\n",
      "Epoch 64/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6364 - acc: 0.8365 - val_loss: 0.7345 - val_acc: 0.7440\n",
      "Epoch 65/100\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.6480 - acc: 0.8325 - val_loss: 1.4386 - val_acc: 0.7758\n",
      "Epoch 66/100\n",
      "78/78 [==============================] - 39s 503ms/step - loss: 0.6378 - acc: 0.8327 - val_loss: 0.5816 - val_acc: 0.8509\n",
      "Epoch 67/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6238 - acc: 0.8324 - val_loss: 0.8868 - val_acc: 0.7730\n",
      "Epoch 68/100\n",
      "78/78 [==============================] - 39s 502ms/step - loss: 0.6350 - acc: 0.8347 - val_loss: 0.8476 - val_acc: 0.6957\n",
      "Epoch 69/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6285 - acc: 0.8377 - val_loss: 0.7181 - val_acc: 0.7807\n",
      "Epoch 70/100\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.6287 - acc: 0.8360 - val_loss: 0.7864 - val_acc: 0.7440\n",
      "Epoch 71/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6121 - acc: 0.8341 - val_loss: 0.8705 - val_acc: 0.7275\n",
      "Epoch 72/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6081 - acc: 0.8408 - val_loss: 0.7829 - val_acc: 0.7823\n",
      "Epoch 73/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6035 - acc: 0.8419 - val_loss: 0.7784 - val_acc: 0.7560\n",
      "Epoch 74/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.5936 - acc: 0.8404 - val_loss: 0.6014 - val_acc: 0.8361\n",
      "Epoch 75/100\n",
      "78/78 [==============================] - 39s 504ms/step - loss: 0.6000 - acc: 0.8411 - val_loss: 0.8254 - val_acc: 0.7736\n",
      "Epoch 76/100\n",
      "78/78 [==============================] - 39s 505ms/step - loss: 0.6160 - acc: 0.8443 - val_loss: 0.5912 - val_acc: 0.8547\n",
      "Epoch 77/100\n",
      "78/78 [==============================] - 39s 502ms/step - loss: 0.6227 - acc: 0.8335 - val_loss: 0.7319 - val_acc: 0.7884\n",
      "Epoch 78/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.5817 - acc: 0.8504 - val_loss: 0.6007 - val_acc: 0.8394\n",
      "Epoch 79/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.6202 - acc: 0.8401 - val_loss: 0.8681 - val_acc: 0.7385\n",
      "Epoch 80/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.6079 - acc: 0.8419 - val_loss: 0.7710 - val_acc: 0.7604\n",
      "Epoch 81/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.6174 - acc: 0.8412 - val_loss: 0.8550 - val_acc: 0.7198\n",
      "Epoch 82/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.6020 - acc: 0.8385 - val_loss: 0.6736 - val_acc: 0.7873\n",
      "Epoch 83/100\n",
      "78/78 [==============================] - 39s 503ms/step - loss: 0.5861 - acc: 0.8482 - val_loss: 0.6728 - val_acc: 0.7873\n",
      "Epoch 84/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.5821 - acc: 0.8471 - val_loss: 0.9768 - val_acc: 0.7127\n",
      "Epoch 85/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.5887 - acc: 0.8499 - val_loss: 0.6561 - val_acc: 0.8174\n",
      "Epoch 86/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.5798 - acc: 0.8470 - val_loss: 0.5776 - val_acc: 0.8322\n",
      "Epoch 87/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.5863 - acc: 0.8496 - val_loss: 1.5968 - val_acc: 0.7434\n",
      "Epoch 88/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.6184 - acc: 0.8454 - val_loss: 0.6798 - val_acc: 0.8065\n",
      "Epoch 89/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.5998 - acc: 0.8538 - val_loss: 0.9640 - val_acc: 0.7012\n",
      "Epoch 90/100\n",
      "78/78 [==============================] - 39s 506ms/step - loss: 0.5854 - acc: 0.8510 - val_loss: 0.5918 - val_acc: 0.8558\n",
      "Epoch 91/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6008 - acc: 0.8413 - val_loss: 1.4247 - val_acc: 0.6946\n",
      "Epoch 92/100\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.6406 - acc: 0.8397 - val_loss: 0.8926 - val_acc: 0.7182\n",
      "Epoch 93/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.5842 - acc: 0.8539 - val_loss: 0.5688 - val_acc: 0.8553\n",
      "Epoch 94/100\n",
      "78/78 [==============================] - 39s 503ms/step - loss: 0.5702 - acc: 0.8576 - val_loss: 0.5486 - val_acc: 0.8701\n",
      "Epoch 95/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.5607 - acc: 0.8592 - val_loss: 0.5954 - val_acc: 0.8438\n",
      "Epoch 96/100\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.5528 - acc: 0.8610 - val_loss: 0.5976 - val_acc: 0.8366\n",
      "Epoch 97/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.5486 - acc: 0.8583 - val_loss: 0.8918 - val_acc: 0.7330\n",
      "Epoch 98/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.5858 - acc: 0.8500 - val_loss: 0.5967 - val_acc: 0.8410\n",
      "Epoch 99/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.5436 - acc: 0.8600 - val_loss: 0.6187 - val_acc: 0.8213\n",
      "Epoch 100/100\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.5664 - acc: 0.8540 - val_loss: 0.6594 - val_acc: 0.8322\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "# Model Training\n",
    "# 11/09/2019 \n",
    "#\n",
    "#######################################################\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import os\n",
    "from math import floor\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from ISY5002_CA2_02_ModelDefinitions import createModel, my_preprocess\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as VGG16_preprocess_input\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as ResNet50_preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as InceptionV3_preprocess_input\n",
    "\n",
    "# import sys\n",
    "\n",
    "# defining global variables\n",
    "DEBUG_MODE = False\n",
    "image_path = \"./Resized\"\n",
    "seed        = 29 # fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "optmz       = 'adam'    # optimizers.RMSprop(lr=0.0001)\n",
    "modelnameBase   = 'CA2'\n",
    "num_classes = 3\n",
    "\n",
    "channel = 3\n",
    "num_epochs = 100\n",
    "\n",
    "# hyperparameters\n",
    "bsize = 32\n",
    "rng_rot = 0\n",
    "rng_zoom = 0.1\n",
    "rng_bright = [0.01, 0]\n",
    "rng_channel = 0.1\n",
    "opt_hflip = True\n",
    "opt_vflip = False\n",
    "\n",
    "def create_summarise_plot(size, channel, index = 0):\n",
    "    imgrows = size\n",
    "    imgclms = size\n",
    "    model = createModel(imgrows, imgclms, channel, index) # for training\n",
    "    # modelGo = createModel() # for final testing\n",
    "    model.summary()\n",
    "\n",
    "    # Plot structure of network\n",
    "    #from tensorflow.keras.utils import plot_model\n",
    "    #plot_model(model, to_file='ISY5002_CA2_NN_' + str(index) + '.pdf', show_shapes=True, show_layer_names=False, rankdir='TB') \n",
    "\n",
    "    return model\n",
    "\n",
    "def createIterators(size, index=0):\n",
    "    imgrows = size\n",
    "    imgclms = size\n",
    "\n",
    "    preprocessing_fn = my_preprocess\n",
    "    if (index > 90):\n",
    "        # Using pretrained datasets - have to use their preprocess functions\n",
    "        if (index == 90):\n",
    "            preprocessing_fn = VGG16_preprocess_input\n",
    "        elif (index == 91):\n",
    "            preprocessing_fn = ResNet50_preprocess_input\n",
    "        elif (index == 92):\n",
    "            preprocessing_fn = InceptionV3_preprocess_input\n",
    "    datagen = ImageDataGenerator(preprocessing_function = preprocessing_fn)\n",
    "    datagenTrain = ImageDataGenerator(preprocessing_function = preprocessing_fn, \n",
    "        rotation_range=rng_rot, zoom_range=rng_zoom, \n",
    "        horizontal_flip=opt_hflip, vertical_flip=opt_vflip) \n",
    "        #brightness_range = rng_bright, channel_shift_range = rng_channel)\n",
    "    \n",
    "    train_it = datagenTrain.flow_from_directory('./Resized/train/', class_mode='categorical', target_size=(imgrows, imgclms), batch_size=bsize, color_mode='rgb')\n",
    "    val_it = datagen.flow_from_directory('./Resized/validation/', class_mode='categorical', target_size=(imgrows, imgclms), batch_size=bsize, color_mode='rgb')\n",
    "    # test_it = datagen.flow_from_directory('./Resized/test/', class_mode='categorical', target_size=(imgrows, imgclms), batch_size=1, color_mode='rgb')\n",
    "\n",
    "    n_train = sum([len(files) for r, d, files in os.walk('./Resized/train/')])\n",
    "    n_val = sum([len(files) for r, d, files in os.walk('./Resized/validation/')])\n",
    "    # n_test = sum([len(files) for r, d, files in os.walk('./Resized/test/')])\n",
    "\n",
    "    batchX, batchy = train_it.next()\n",
    "    print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
    "\n",
    "    return train_it, val_it, n_train, n_val  \n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # ------ CHANGE THESE ------\n",
    "    index = 15\n",
    "    size = 224\n",
    "    # --------------------------\n",
    "\n",
    "\n",
    "    modelname = modelnameBase + \"_\" + str(index) + \"_\" + str(size)\n",
    "\n",
    "    # Create model and summary\n",
    "    train_it, val_it, n_train, n_val= createIterators(size, index)\n",
    "    model = create_summarise_plot(size, channel, index)\n",
    "\n",
    "    # Create checkpoint for the training\n",
    "    # This checkpoint performs model saving when\n",
    "    # an epoch gives highest testing accuracy\n",
    "    filepath        = modelname + \".hdf5\"\n",
    "    checkpoint      = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "    # Log the epoch detail into csv\n",
    "    csv_logger      = CSVLogger(modelname +'.csv')\n",
    "    callbacks_list  = [checkpoint,csv_logger]\n",
    "    \n",
    "    # steps_per_epoch = total training data across all classes / batch size\n",
    "    # validation_steps = number of batches in validation dataset defining 1 epoch\n",
    "    model.fit_generator(\n",
    "        train_it, steps_per_epoch=floor(n_train/bsize), \n",
    "        validation_data=val_it, \n",
    "        validation_steps=floor(n_val/bsize),\n",
    "        epochs=num_epochs, callbacks = callbacks_list )\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ISY5002_CA2_03_ModelTrain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
